{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b22b58e-1420-4d32-ad31-043cdd9093e9",
   "metadata": {},
   "source": [
    "# 생성 모델링\n",
    "## 용어 정리\n",
    "* 표본 공간 : 샘플 x가 가질 수 있는 모든 값의 집합  \n",
    "* 확률 밀도 함수 : p(x)는 표본 공간의 포인트 x를 0과 1사이의 숫자에 매핑하는함수  \n",
    "* 표본 공간의 모든 포인트에 대한 확률 밀도 함수의 합은 1이 되어야 잘 정의된 확률 분포  \n",
    "* 모수 모델 : Pseta(X)는 한정된 개수의 파라미터 seta를 사용하여 묘사하는 확률 밀도 함수의 한 종류이다  \n",
    "* 최대 가능도 추청 : 파라미터 집합 seta의 가능도(likehood) 는 샘플 포인트 x가 주어졌을 때 seta의 알맞은 정도를 측정하는 함수  \n",
    "* 즉 샘플 포인트 x가 주어졌을 때 seta의 가능도는 포인트 x에서 seta로 정의된 확률 밀도 함수의 값을 정의합니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9149a366-60c5-4ec6-bea5-32b2b6b0fdbd",
   "metadata": {},
   "source": [
    "## 첫 번째 확률적 생성 모델\n",
    "50개의 패션 샘풀로 구성되 있는 것을 사용할려고 한다.  \n",
    "이 데이터 셋은 현재 행성에서 볼 수 있는 N=50 패션 샘플로 구성되어 있다.  \n",
    "이 데이터 셋은 5개의 특성 (accessoriesType, clothingColor, clothingType, hairColor, topType)으로 설명할 수 있다.  \n",
    "\n",
    "* 7가지 머리 모양 (topType)\n",
    "* 6가지 머리 색깔 (hairColor)\n",
    "* 3가지 안경 (accessoriesType)\n",
    "* 4가지 옷 (clothingType)\n",
    "* 8가지 옷 색깔 (clothingColor)\n",
    "\n",
    "총 4,032개의 특성 조합이 있으므로 이 표본 공간에는 4,032개의 포인트가 있다.  \n",
    "일부 특성이 다른 것보다 우선되는 어떤 분포 $P_{data}$로 이 데이터셋이 생성되었다고 가정해보죠. 예를 들어 은백색 머리, 둥글게 파인 티셔츠가 인기가 높을 것 같다.  \n",
    "문제는 명확하게 $P_{data}$를 모른다는 것입니다. 가지고 있는 것은 $P_{data}$로 생성한 샘플 데이터셋 X 뿐입니다. ( 즉 seta를 모르겠다는 건 어떤 사건만 존재한다 )  \n",
    "생성 모델의 목표는 이 샘플을 사용하여 $P_{data}$에서 생성한 샘플을 완벽하게 흉내 내는 $P_{model}$을 만드는 것입니다. ( 최대한 비슷한 모수 모델을 만드는 것 )  \n",
    "이를 위해 단순하게 주어진 데이터를 기반으로 가능한 특성의 조합마다 확률을 부여할 수 있습니다. 이 모수 모델은 d=4,031의 파라미터를 가집니다. 파라미터 하나가 표본 공간의 가능한 포인트마다 대응됩니다. 마지막 파라미터의 값은 전체 합이 1이 되기 위해 자동으로 결정되므로 파라미터의 개수는 전체 포인트 개수보다 1 작습니다. 즉 예측할 모델의 파라미터는 ($\\theta_1,\\ldots,\\theta_{4031}$) 입니다.  \n",
    "이런 종류의 모수 모델을 다항분포라고하며 각 파라미터의 최대 가능도 추정값 $\\hat\\theta_j$는 다음과 같이 계산합니다.  \n",
    "### $\\hat{\\theta}= {n_j\\over N}$\n",
    "여기서 $n_j$는 데이터셋에서 발견된 조합$j$의 횟수 입니다. $N=50$은 전체 샘플의 개수 입니다.  \n",
    "다른 말로 하면, 각 파라미터의 추정값은 해당되는 패션 조합이 데이터셋에 등장하는 비율입니다. 예를 들어 다음과 같은 조합(이를 조합 1이라 부르겠습니다)은 데이터셋에서 두 번 등장 합니다.  \n",
    "#### (LognHairStraight, Red, Round, ShirtScoopNect, White)\n",
    "그러므로 이 조합에 대한 파라미터 추정값은 다음과 같습니다.\n",
    "### $\\hat\\theta_1 = 2/50 = 0.04$\n",
    "\n",
    "또 다른 예로 다음 조합(이를 조합 2라고 부르겠습니다)은 데이터셋에 전혀 등장하지 않습니다\n",
    "#### (LongHairStraingt, Red, Round, ShirtScoopNext, Blue01(\n",
    "그러므로 이 조합에 대한 파라미터 추정값은 다음과 같습니다\n",
    "### $\\hat\\theta_2 = 0/50 = 0$\n",
    "이런 식으로 모든 $\\hat\\theta_j$값을 계산하여 표본 공간의 분포를 정의할 수 있습니다. 이 분포에서 샘플링을 수행할 수 있기 때문에 이 목록을 생성 모델이라고 부룰 수 있습니다. 하지만 중요한 점에서 문제가 발생합니다. 원본 데이터셋 $X$에 없는 조합 $\\hat\\theta_j = 0$이기 때문에 본 적 없는 샘플은 생성할 수 없습니다.  \n",
    "이 문제를 해결하려면 가능한 특성의 조합마다 가상의 등장 횟수 1을 더합니다. 이를 **가법 평활화(additive smoothing)** 라고 합니다. 이 모델의 파라미터에 대한 최대 가능도 추정값은 다음과 같습니다.\n",
    "### $\\hat\\theta_j = {n_j + 1 \\over N + d}$\n",
    "여기서 d 는 파라미터의 개수 즉 4,032개를 말하고 있다.\n",
    "\n",
    "이제 원본 데이터셋에 있지 않은 것을 포함하여 모든 개별 조합은 0이 아닌 샘플링 확률을 가집니다. 하지만 원본 데이터셋에 없는 포인트가 등장할 확률이 단순히 상수 이므로 여전히 만족할 만한 생성 모델은 아닙니다. 이런 모델로 피카소 그림을 생성한다면 진짜 피카소 그림과 매우 조금만 다른 복제본이 만들어지도록 랜덤한 픽셀조합에는 조금만 가중치가 부여될 것 입니다.  \n",
    "이상적으로는 생성 모델이 데이터셋에 존재하는 포인트에 확률을 모두 부여하는 것이 아니라 표본 공간에 가능성이 있다고 믿는 영역의 가중치를 높이기를 바랍니다. 이는 데이터에서 학습한 잠재된 구조를 바탕으로 수행됩니다.  \n",
    "이런 작업을 수행하려면 다른 모수 모델을 선택해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d343650a-023f-4213-82ba-8172fa6cd423",
   "metadata": {},
   "source": [
    "## 나이브 베이즈\n",
    "**나이브 베이즈** 모델은 간단한 가정을 사용하여 추정할 파라미터의 개수를 크게 줄여 줍니다. 각 특성 $x_j$가 다른 모든 특성 $x_k$에 독립적이라고 단순하게 가정합니다. 예를 들어 로들 데이터셋으로 머리 색깔을 고르는 것이 옷 종류를 선택하는 것에 영향을 끼치지 않다고 생각하는 것 입니다. 또 쓰고 있는 안경의 종류가 머리 모양에 영향을 미치지 않스빈다. 이론적으로 말하면 모든 특성 $x_j,x_k$에 대해 다음과 같습니다.\n",
    "### $p(x_j|x_k) = p(x_j)$\n",
    "이를 나이브 베이즈 가정이라고 합니다. 이런 가정을 적용하기 위해 먼저 확률의 연쇄 법칙(chain rule)을 사용하여 확률 밀도 함수를 조건부 확률의 곱으로 작성합니다. \n",
    "다음은 p40에서 확인하세요,,, 쓰기 귀찮네요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51171db-df1f-40ab-b995-611d94e18e94",
   "metadata": {},
   "source": [
    "## 표현학습\n",
    "표현학습 이면에 있느 핵심 아이디어는 고차원 표본 공간을 직접 모델링하는 것이 아니라 대신 저차원의 **잠재공간(latent space)** 을 사용해 훈련 세트의 각 샘플을 표현하고 이를 원본 공간의 포인트에 매핑하는 것입니다. 다른 말로 하면, 잠재 공간의 각 포인트는 어떤 고차원 이미지에 대한 표현입니다.  \n",
    "실제로 이것은 무엇을 의미할까요? 회색 비스킷 깡통 이미지로 이루어진 훈련 세트가 있다고 가정해보죠.  \n",
    "깡통의 높이와 너비 2개의 특성으로 각 깡통을 고유하게 표현할 수 있습니다. 높이와 너비가 주어지면 훈련 세트에 없더라도 이에 맞는 깡통을 그릴 수 있습니다. 하지만 컴퓨터에게는 쉬운 작업이 아닙니다. 먼저 높이와 너비가 이 데이터셋을 가장 잘 묘사하는 두 개의 잠재 공간 차원이라는 것을 알아야 합니다. 그다음 매핑 함수 $f$를 학습하여 이 공간의 한 포인트를 회색 비스킷 깡통 이미지에 매핑해야 합니다. 비스킷 깡통의 잠재 공간과 생성 과정이 나타나 있습니다.  \n",
    "딥러닝은 다양한 방법으로 아주 복잡한 매핑 함수 $f$를 학습할 수 있습니다. 이 책의 나머지 장에서 가장 중요한 기법들을 알아보겠습니다. 지금은 표현학습이 달성하려는 것을 고수준에서 이해하는 것으로 충분합니다.  \n",
    "표현학습을 사용하는 장점 중 하나는 의미 있는 잠재 공간에서 이미즈이 고수준 속성에 영향을 미치는 연산을 수행할 수 있다는 것입니다. 비스킷 깡통 이미지가 주어졌을 때 높이를 크게 하려면 개별 픽셀을 어떻게 조정해야 할지 알지 못합니다. 하지만 잠재 공간에서는 간단히 잠재 공간의 높이 차원에 1을 더하고 매핑 함수를 적용해 이미지를 얻을 수 있습니다. 이어지는 장에서 비슷킷 깡통 대신 얼굴 이미젱 적용한 구체적인 예제를 보겠습니다.  \n",
    "표현학습이 사람에게는 매우 자연스럽기 때문에 힘들이지 않고 할 수 있다는 것이 얼마나 놀라운지 생각해 본 적이 없을 것 입니다. 당신의 외모를 모르면서 군중 속에서 당신을 찾고 있는 사람에게 자신을 설명한다고 가정해보죠. 1번 머리 픽셀의 색깔 그 다음 2번 픽셀, 3번 픽셀으로 시작하지 않을 것입니다. 대신 그 사람이 일반적으로 평균적인 사람의 모습에 대해 알고 있을 것이라고 생각합니다. 그 다음 이련의 픽셀로 표현된 특성으로 이 가정을 수정합니다. 예를 들면 *나는 금발 머리에 안경을 썼습니다* 와 같습니다. 이런 문장 10개 정도만 있으면 그 사람은 주어진 설명을 픽셀로 바꾸어 머릿속에 당신의 이미지를 생성할 수 있스빈다. 이미지가 완벽하지 않을 수 이씃빈다. 하짐나 실제 당신의 모습과 충분히 가까워 당신을 본 적 이 없더라도 수백명의 사람들 사이에서 당신을 찾을 수 있을 것입니다.  \n",
    "표현핛브은 머리색깔, 키와 같이 미리 주어진 특성에 값을 할당하지 않는다는 점을 기억하세요. 표현학습의 강점은 샘플을 묘사하는 데 가장 뛰어난 특성과 이런 특성을 원본 데이터에서 추출하는 방벙르 학습합니다. 수학적으로 말하면 데이터의 **비선형 매니폴드** 를 찾고 이 공간을 완전하게 설명하기 위해 필요한 차원을 구성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941a149f-3f5d-41bd-b1ec-e2de96572b84",
   "metadata": {},
   "source": [
    "## 환경 설정\n",
    "이 예제를 사용하라면 이 책의 깃허브저장소를 클론해야합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ef83c0a-b5fd-4ae3-b99a-27c7a10b6b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'GDL_code'...\n",
      "Updating files:  50% (39/77)\n",
      "Updating files:  51% (40/77)\n",
      "Updating files:  53% (41/77)\n",
      "Updating files:  54% (42/77)\n",
      "Updating files:  55% (43/77)\n",
      "Updating files:  57% (44/77)\n",
      "Updating files:  58% (45/77)\n",
      "Updating files:  59% (46/77)\n",
      "Updating files:  61% (47/77)\n",
      "Updating files:  62% (48/77)\n",
      "Updating files:  63% (49/77)\n",
      "Updating files:  64% (50/77)\n",
      "Updating files:  66% (51/77)\n",
      "Updating files:  67% (52/77)\n",
      "Updating files:  68% (53/77)\n",
      "Updating files:  70% (54/77)\n",
      "Updating files:  71% (55/77)\n",
      "Updating files:  72% (56/77)\n",
      "Updating files:  74% (57/77)\n",
      "Updating files:  75% (58/77)\n",
      "Updating files:  76% (59/77)\n",
      "Updating files:  77% (60/77)\n",
      "Updating files:  79% (61/77)\n",
      "Updating files:  80% (62/77)\n",
      "Updating files:  81% (63/77)\n",
      "Updating files:  83% (64/77)\n",
      "Updating files:  84% (65/77)\n",
      "Updating files:  85% (66/77)\n",
      "Updating files:  87% (67/77)\n",
      "Updating files:  88% (68/77)\n",
      "Updating files:  89% (69/77)\n",
      "Updating files:  90% (70/77)\n",
      "Updating files:  92% (71/77)\n",
      "Updating files:  93% (72/77)\n",
      "Updating files:  94% (73/77)\n",
      "Updating files:  96% (74/77)\n",
      "Updating files:  97% (75/77)\n",
      "Updating files:  98% (76/77)\n",
      "Updating files: 100% (77/77)\n",
      "Updating files: 100% (77/77), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/rickiepark/GDL_code.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497549c3-1cc4-4bca-a148-3fc0b2157c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
