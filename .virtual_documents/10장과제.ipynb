import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential


import requests
requests.packages.urllib3.disable_warnings()
import ssl

try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    # Legacy Python that doesn't verify HTTPS certificates by default
    pass
else:
    # Handle target environment that doesn't support HTTPS verification
    ssl._create_default_https_context = _create_unverified_https_context


from tensorflow.keras.layers import *

(X_train, y_train) ,(X_test,y_test) = keras.datasets.cifar10.load_data()


print(X_train.shape)
print(y_train.shape)


# 총 0부터 9까지 10개의 정답이 있다.
labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog',
          'horse', 'ship', 'truck']

# 이미지 사이즈
IMG_SIZE = (32, 32)
# 이미지 형태
IMG_SHAPE = (32, 32, 3)
# 배치 사이즈
BATCH_SIZE = 32


# 두 번째 영상(트럭을)을 화면에 표시한다.
plt.figure()
plt.imshow(X_train[1])
plt.colorbar()


plt.figure(figsize=(10,10))
for i in range(9):
    ax = plt.subplot(3,3,i+1)
    plt.imshow(X_train[i])
    plt.title(labels[y_train[i][0]])
    plt.axis('off')
plt.show()


X_train_norm = X_train / 255.0
X_test_norm = X_test / 255.0


model = Sequential()
model.add(Conv2D(64, activation = 'relu', kernel_size = (3,3)))
model.add(MaxPooling2D(pool_size = (2,2)))
model.add(Conv2D(32, activation = 'relu', kernel_size = (3,3)))
model.add(Flatten(input_shape= (32, 32, 3)))
model.add(Dense(80, activation='relu'))
model.add(Dense(10, activation='softmax'))


model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', \
              metrics=['accuracy'])


history = model.fit(X_train_norm, y_train, epochs=10, verbose=1, validation_split=0.3)


plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['loss', 'val_loss'], loc='lower right')
plt.show()


plt.figure()
plt.imshow(X_test[0])
y_pred = model.predict(X_test)
print("정답=", labels[y_test[0][0]])
print("예측 레이블=", labels[np.argmax(y_pred[0])])


# 데이터증강을 위한 라이브러리
from numpy import expand_dims
from tensorflow.keras.preprocessing.image import load_img, img_to_array


image = load_img('dog.jpeg')
array = img_to_array(image)
sample = expand_dims(array, axis=0)

# 차원이 하나 늘어난 것을 볼 수 있다.
print(sample.shape)


from tensorflow.keras.preprocessing.image import ImageDataGenerator

dataget = ImageDataGenerator(rescale=1./255, rotation_range=90,
                             brightness_range=[0.8, 1.0],
                             width_shift_range=0.2,
                             zoom_range=[0.8, 1.2],
                             height_shift_range=0.2)

obj = dataget.flow(sample, batch_size=1)


fig = plt.figure(figsize=(10, 10))
for i in range(8):
    plt.subplot(3, 3, i+1)
    image = obj.next()
    plt.imshow(image[0])
    plt.axis('off')


# 트레인과 테스트 이미지 증강을 만들어주자
train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2,
                                   zoom_range=0.2, horizontal_flip=True)

test_datagen = ImageDataGenerator(rescale=1./255)

train_datagen.fit(X_train)
test_datagen.fit(X_test)


train_generator = train_datagen.flow(
    X_train,
    y_train,
    batch_size=BATCH_SIZE)

test_generator = test_datagen.flow(
    X_test,
    y_test,
    batch_size=BATCH_SIZE)


# 원하는 콜백함수 생성
from keras.callbacks import EarlyStopping
earlystop = EarlyStopping(patience=7)


history = model.fit_generator(train_generator,
                    steps_per_epoch=len(X_train) / BATCH_SIZE, epochs=10)


plt.plot(history.history['accuracy'])
plt.plot(history.history['accuracy'])
plt.title('accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.show()


inputs = tf.keras.Input(shape=IMG_SHAPE)
x = tf.keras.layers.Flatten()(inputs)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(512, activation='relu')(x)
x = tf.keras.layers.BatchNormalization()(x)
x = tf.keras.layers.Dropout(0.3)(x)
outputs = tf.keras.layers.Dense(10, activation='softmax')(x)

model = tf.keras.Model(inputs,outputs)


model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])


history = model.fit(X_train, y_train, epochs=100, verbose=1, callbacks=[earlystop],
                    validation_split=0.3)


model.fit_generator(train_generator,
                    steps_per_epoch=len(X_train) / BATCH_SIZE, epochs=10)


from keras.applications.resnet_v2 import ResNet50V2,preprocess_input, decode_predictions

resnet = ResNet50V2(include_top=False, weights='imagenet',
                    input_shape=IMG_SHAPE)

preprocess_input = preprocess_input

# 모델설계
inputs = tf.keras.Input(shape=IMG_SHAPE)
x = preprocess_input(inputs)
x = resnet(x)
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Flatten()(x)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(512, activation='relu')(x)
x = tf.keras.layers.BatchNormalization()(x)
x = tf.keras.layers.Dropout(0.3)(x)
outputs = tf.keras.layers.Dense(10, activation='softmax')(x)

model = tf.keras.Model(inputs, outputs)


model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])


history = model.fit(d, y_train, epochs=100, verbose=1, callbacks=[earlystop],
                    validation_split=0.3)


x = resnet.output
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(512, activation='relu')(x)
outputs = tf.keras.layers.Dense(10, activation='softmax')(x)

model = tf.keras.Model(inputs=resnet.input, outputs=outputs)


for layer in model.layers[:20]:
    layer.trainable = False
for layer in model.layers[20:]:
    layer.trainable = True


model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
step_size_train = train_generator.n // train_generator.batch_size


model.fit_generator(train_generator,
                    steps_per_epoch=len(X_train) / BATCH_SIZE, epochs=10)
