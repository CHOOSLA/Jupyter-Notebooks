get_ipython().getoutput("wget http://www.timeseriesclassification.com/Downloads/FordA.zip")


get_ipython().getoutput("unzip FordA.zip")


import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import SimpleRNN
from tensorflow.keras.layers import Dense
import matplotlib.pyplot as plt
import pandas as pd


def make_sample(data, window):
    train = []
    target = []
    for i in range(len(data)-window):
        train.append(data[i:i+window])
        target.append(data[i+window])
    return np.array(train), np.array(target)


seq_data = []
for i in np.arange(0,1000):
    seq_data += [[np.sin( np.pi * i * 0.01)]]
X, y = make_sample(seq_data, 10)


model = Sequential()
model.add(SimpleRNN(10, activation='tanh', input_shape=(10,1)))
model.add(Dense(1, activation='tanh'))
model.compile(optimizer='adam', loss='mse')


history = model.fit(X, y, epochs=100, verbose=1)
plt.plot(history.history['loss'], label='loss')
plt.show()


seq_data = []
for i in np.arange(0, 1000):
    seq_data += [[np.cos(np.pi*i*0.01)]]

X, y = make_sample(seq_data, 10)

y_pred = model.predict(X, verbose=0)
plt.plot(np.pi*np.arange(0, 990)*0.01, y_pred)
plt.plot(np.pi*np.arange(0, 990)*0.01, y)
plt.show()


def readucr(filename):
    data = np.loadtxt(filename, delimiter="\t")
    y = data[:, 0]
    x = data[:, 1:]
    return x, y.astype(int)


root_url = "https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/"

x_train, y_train = readucr(root_url + "FordA_TRAIN.tsv")
x_test, y_test = readucr(root_url + "FordA_TEST.tsv")


print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)


print(y_train[5])


classes = np.unique(y_train, axis=0)

plt.figure()
for c in classes:
    c_x_train = x_train[y_train == c]
    plt.plot(c_x_train[0], label="class " + str(c))
plt.legend(loc="best")
plt.show()
plt.close()


# 데이터 전처리
## 데이터 표준화


# 우리의 타임시리즈는 이미 하나의 길이이지만, 그들의 값들은 다양한 길이를 가지고 있다.
# 이것은 뉴럴 네트워크에 적합하지 않다. 보통 우리는 입력값을 표준화할 필요가 있다.
# 이러한 데이터셋은 특히, z-normalized된 것인데, 각각의 타임시리즈 샘플들은
# 평균이 0이고 표준편차는 1이다.
# 이러한 타입의 표준화는 타임시리즈 분류에 매우 보현화되어 있다.

# 여기에 사용된 시계열 데이터는 단변량이다.
# 즉, 시계열 예제당 하나의 채널만 있음을 의미한다는 것이다.
# 우리는 그러므로 numpy를 통해 간단한 reshaping을 사용하여
# 하나의 채널이 있는 다변수 시계열로 변환시킬 것이다.
x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))
x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))
print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)


# spase_categorical_crossentropy를 사용하기 위해 class의 갯수를 저장한다.
num_classes = len(np.unique(y_train))


# np.random.permutation은 무작위로 섞인 배열을 만든다.
idx = np.random.permutation(len(x_train))

# 넘파이의 인덱스 연산을 사용한다.
x_train = x_train[idx]
y_train = y_train[idx]


# 라벨들을 양의 정수로 바꿔준다.
y_train[y_train == -1] = 0
y_test[y_test == -1] = 0


print(y_train)


# 모델 설계
from tensorflow import keras

def make_model(input_shape):
    input_layer = keras.layers.Input(input_shape)

    conv1 = keras.layers.Conv1D(filters=64, kernel_size=3, padding="same")(input_layer)
    conv1 = keras.layers.BatchNormalization()(conv1)
    conv1 = keras.layers.ReLU()(conv1)

    conv2 = keras.layers.Conv1D(filters=64, kernel_size=3, padding="same")(conv1)
    conv2 = keras.layers.BatchNormalization()(conv2)
    conv2 = keras.layers.ReLU()(conv2)

    conv3 = keras.layers.Conv1D(filters=64, kernel_size=3, padding="same")(conv2)
    conv3 = keras.layers.BatchNormalization()(conv3)
    conv3 = keras.layers.ReLU()(conv3)

    gap = keras.layers.GlobalAveragePooling1D()(conv3)

    output_layer = keras.layers.Dense(num_classes, activation="softmax")(gap)

    return keras.models.Model(inputs=input_layer, outputs=output_layer)


model = make_model(input_shape=x_train.shape[1:])
keras.utils.plot_model(model, show_shapes=True)


epochs = 500
batch_size = 32

callbacks = [
    keras.callbacks.ReduceLROnPlateau(
        monitor="val_loss", factor=0.5, patience=20, min_lr=0.0001
    ),
    keras.callbacks.EarlyStopping(monitor="val_loss", patience=50, verbose=1),
]
model.compile(
    optimizer="adam",
    loss="sparse_categorical_crossentropy",
    metrics=["sparse_categorical_accuracy"],
)
history = model.fit(
    x_train,
    y_train,
    batch_size=batch_size,
    epochs=epochs,
    callbacks=callbacks,
    validation_split=0.2,
    verbose=1,
)


test_loss, test_acc = model.evaluate(x_test, y_test)

print("Test accuracy", test_acc)
print("Test loss", test_loss)


metric = "sparse_categorical_accuracy"
plt.figure()
plt.plot(history.history[metric])
plt.plot(history.history["val_" + metric])
plt.title("model " + metric)
plt.ylabel(metric, fontsize="large")
plt.xlabel("epoch", fontsize="large")
plt.legend(["train", "val"], loc="best")
plt.show()
plt.close()


def make_LSTM_model(input_shape):
    input_layer = keras.layers.Input(input_shape)

    lstm1 = keras.layers.LSTM(100, activation='tanh', return_sequnces=False)(input_layer)
    
    output_layer = keras.layers.Dense(num_classes, activation="softmax")(lstm1)

    return keras.models.Model(inputs=input_layer, outputs=output_layer)


lstm_model = make_model(input_shape=x_train.shape[1:])


lstm_model.compile(
    optimizer="adam",
    loss="sparse_categorical_crossentropy",
    metrics=["sparse_categorical_accuracy"],
)


history = lstm_model.fit(
    x_train,
    y_train,
    batch_size=batch_size,
    epochs=epochs,
    callbacks=callbacks,
    validation_split=0.2,
    verbose=1,
)


test_loss, test_acc = lstm_model.evaluate(x_test, y_test)

print("Test accuracy", test_acc)
print("Test loss", test_loss)


metric = "sparse_categorical_accuracy"
plt.figure()
plt.plot(history.history[metric])
plt.plot(history.history["val_" + metric])
plt.title("model " + metric)
plt.ylabel(metric, fontsize="large")
plt.xlabel("epoch", fontsize="large")
plt.legend(["train", "val"], loc="best")
plt.show()
plt.close()


## 10장 문제

